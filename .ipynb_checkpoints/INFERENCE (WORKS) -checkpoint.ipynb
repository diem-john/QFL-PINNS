{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40cd50b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred during the forecasting process: 'station_latitude'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from haversine import haversine, Unit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 0. Model and Helper Function Definitions ---\n",
    "\n",
    "# Define the Hybrid Model with PINN (Based on E2E Process .ipynb Cell 34)\n",
    "class HybridModelPINN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, sequence_length,\n",
    "                 embedding_dim=128, n_head=4, num_transformer_layers=4,\n",
    "                 conv_channels=64, kernel_size=3, pool_kernel=2,\n",
    "                 hidden_dense=512):\n",
    "        super(HybridModelPINN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_head = n_head\n",
    "        \n",
    "        self.linear_projection = nn.Linear(input_size, embedding_dim)\n",
    "        self.positional_encoding = self._get_positional_encoding(sequence_length, embedding_dim)\n",
    "        self.register_buffer('positional_encoding_buffer', self.positional_encoding)\n",
    "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=n_head, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, num_layers=num_transformer_layers)\n",
    "        self.conv_layer = nn.Conv1d(embedding_dim, conv_channels, kernel_size, padding='same')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pooling_layer = nn.MaxPool1d(pool_kernel)\n",
    "\n",
    "        self.conv_output_length = (sequence_length + 2 * (kernel_size // 2) - (kernel_size - 1) - 1) + 1\n",
    "        self.pooled_output_length = self.conv_output_length // pool_kernel\n",
    "\n",
    "        self.dense1 = nn.Linear(conv_channels * self.pooled_output_length + embedding_dim * sequence_length, hidden_dense) \n",
    "        self.dense2 = nn.Linear(hidden_dense, output_size)\n",
    "        self.u_dense = nn.Linear(hidden_dense, output_size)\n",
    "        self.v_dense = nn.Linear(hidden_dense, output_size)\n",
    "        self.p_dense = nn.Linear(hidden_dense, output_size)\n",
    "\n",
    "    def _get_positional_encoding(self, seq_len, d_model):\n",
    "        position = torch.arange(seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe = torch.zeros(seq_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        return pe.squeeze(1).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.linear_projection(x)\n",
    "        positional_encoding = self.positional_encoding_buffer[:, :embedded.size(1), :]\n",
    "        embedded = embedded + positional_encoding\n",
    "        transformer_out = self.transformer_encoder(embedded)\n",
    "        transformer_out_flattened = transformer_out.view(transformer_out.size(0), -1)\n",
    "\n",
    "        cnn_in = embedded.permute(0, 2, 1)\n",
    "        conv_out = self.relu(self.conv_layer(cnn_in))\n",
    "        pooled_out = self.pooling_layer(conv_out)\n",
    "        pooled_out_flattened = pooled_out.view(pooled_out.size(0), -1)\n",
    "\n",
    "        combined_features = torch.cat((pooled_out_flattened, transformer_out_flattened), dim=1)\n",
    "        dense1_out = self.relu(self.dense1(combined_features))\n",
    "\n",
    "        output = self.dense2(dense1_out)\n",
    "        u_out = self.u_dense(dense1_out)\n",
    "        v_out = self.v_dense(dense1_out)\n",
    "        p_out = self.p_dense(dense1_out)\n",
    "\n",
    "        return output, u_out, v_out, p_out\n",
    "\n",
    "# Define distance calculation function\n",
    "def calculate_distance(row):    \n",
    "    try:\n",
    "        typhoon_loc = (row['lat'], row['lng'])\n",
    "    except:\n",
    "        typhoon_loc = (row['typhoon_lat'], row['typhoon_lng'])\n",
    "    \n",
    "    try:\n",
    "        station_loc = (row['station_latitude'], row['station_longitude'])\n",
    "    except:\n",
    "        station_loc = (row['latitude'], row['longitude'])\n",
    "        \n",
    "    if pd.isnull(typhoon_loc[0]) or pd.isnull(station_loc[0]):\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        return haversine(typhoon_loc, station_loc, unit=Unit.KILOMETERS)\n",
    "    except ValueError as e:\n",
    "        corrected_longitude = typhoon_loc[1]\n",
    "        if corrected_longitude > 180: corrected_longitude = 180\n",
    "        elif corrected_longitude < -180: corrected_longitude = -180\n",
    "        corrected_typhoon_loc = (typhoon_loc[0], corrected_longitude)\n",
    "        return haversine(corrected_typhoon_loc, station_loc, unit=Unit.KILOMETERS)\n",
    "\n",
    "# Define prediction function\n",
    "def predict_wind_speed(model, historical_df, features, scaler_target, SEQUENCE_LENGTH):\n",
    "    model.eval()\n",
    "    \n",
    "    # Get the last SEQUENCE_LENGTH (48 hours) of the 9 features as input\n",
    "    input_sequence_df = historical_df[features].tail(SEQUENCE_LENGTH).copy()\n",
    "    scaled_input_array = input_sequence_df.values\n",
    "    input_tensor = torch.from_numpy(scaled_input_array).float().unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predicted_scaled_output, _, _, _ = model(input_tensor) \n",
    "    \n",
    "    predicted_scaled_output = predicted_scaled_output.squeeze(0).cpu().numpy()\n",
    "    \n",
    "    # Reshape the output to be 2D for inverse transform\n",
    "    predicted_scaled_output = predicted_scaled_output.reshape(-1, 1)\n",
    "    \n",
    "    # Inverse transform to get back the original wind speed values\n",
    "    predicted_wind_speed = scaler_target.inverse_transform(predicted_scaled_output)\n",
    "    \n",
    "    return predicted_wind_speed\n",
    "\n",
    "# --- Configuration ---\n",
    "SEQUENCE_SIZE = 48\n",
    "TARGET_WINDOW = 24\n",
    "station_name = 'Guanyin'\n",
    "\n",
    "# Define the 9 features used for training the weather station model\n",
    "features = ['air_pressure', 'temperature', 'relative_humidity', 'wind_speed', \n",
    "            'wind_direction', 'gust_max', 'gust_max_dir', 'precipitation', 'solar_rad']\n",
    "target_features = ['wind_speed'] \n",
    "input_size = len(features) \n",
    "output_size = TARGET_WINDOW \n",
    "sequence_length = SEQUENCE_SIZE \n",
    "\n",
    "# Initialize the HybridModelPINN model (Weights are random since no training is run here)\n",
    "model = HybridModelPINN(input_size, output_size, sequence_length) \n",
    "\n",
    "\n",
    "# --- STEP 2.1 - 2.3: Exogenous Data Preparation & Typhoon Forecasting ---\n",
    "try:\n",
    "    # 1. Load historical typhoon data - UPDATED TO INCLUDE 'long50'\n",
    "    typhoon_data_hist = pd.read_csv('data/typhoon_data.csv', parse_dates=['Date'], infer_datetime_format=True)\n",
    "    typhoon_data_hist.rename(columns={'Date': 'time'}, inplace=True)\n",
    "    # Filter for the correct 4 features: lat, lng, wind, long50\n",
    "    typhoon_data_hist = typhoon_data_hist[['time', 'lat', 'lng', 'wind', 'long50']].copy() \n",
    "    typhoon_data_hist = typhoon_data_hist[(typhoon_data_hist['time'].dt.year >= 2015) & (typhoon_data_hist['time'].dt.year <= 2021)].copy()\n",
    "\n",
    "    # 2. Load station coordinates\n",
    "    station_coords = pd.read_csv('data/weather_station_coords.csv')\n",
    "    station_coords.rename(columns={'lat': 'station_latitude', 'long': 'station_longitude', 'location': 'station'}, inplace=True)\n",
    "\n",
    "    # 3. Simulate Future Typhoon Track - UPDATED COLUMNS: [lat, lng, wind, long50]\n",
    "    # NOTE: The values for 'long50' are placeholders as the Seq2Seq model is not run here.\n",
    "    predicted_path = np.array([\n",
    "        [20.450680, 132.747116, 26.142002, 26.142002], [20.300367, 133.040436, 23.932819, 23.932819],\n",
    "        [20.229645, 133.010651, 22.949032, 22.949032], [20.209167, 133.002869, 22.560272, 22.560272],\n",
    "        [20.184433, 133.064072, 22.181082, 22.181082], [20.150391, 133.156326, 21.766857, 21.766857],\n",
    "        [20.110056, 133.261307, 21.348244, 21.348244], [20.064110, 133.374283, 20.928129, 20.928129],\n",
    "        [20.007898, 133.509064, 20.474539, 20.474539], [19.938812, 133.671219, 19.968014, 19.968014],\n",
    "        [19.859865, 133.857086, 19.438555, 19.438555], [19.772778, 134.071487, 18.922440, 18.922440],\n",
    "        [19.685184, 134.293747, 18.450138, 18.450138], [19.613235, 134.477036, 18.076469, 18.076469],\n",
    "        [19.539940, 134.666977, 17.720968, 17.720968], [19.429588, 134.959549, 17.229780, 17.229780],\n",
    "        [19.352909, 135.163391, 16.895298, 16.895298], [19.329014, 135.226578, 16.788628, 16.788628],\n",
    "        [19.322208, 135.244492, 16.757080, 16.757080], [19.319834, 135.250671, 16.745668, 16.745668],\n",
    "        [19.318819, 135.253326, 16.740629, 16.740629], [19.318312, 135.254639, 16.738014, 16.738014],\n",
    "        [19.318022, 135.255386, 16.736504, 16.736504], [19.317848, 135.255829, 16.735594, 16.735594]\n",
    "    ])\n",
    "    last_typhoon_time = pd.to_datetime(typhoon_data_hist['time'].iloc[-1])\n",
    "    forecast_times = pd.date_range(start=last_typhoon_time + pd.Timedelta(hours=1), periods=TARGET_WINDOW, freq='H')\n",
    "\n",
    "    predicted_typhoon_df = pd.DataFrame(predicted_path, columns=['lat', 'lng', 'wind', 'long50'])\n",
    "    predicted_typhoon_df['time'] = forecast_times\n",
    "\n",
    "    # 4. Generate Future Exogenous Data (Final Exogenous Data)\n",
    "    station_row = station_coords[station_coords['station'] == station_name].iloc[0]\n",
    "    future_exogenous_df = predicted_typhoon_df.copy()\n",
    "    future_exogenous_df['station_latitude'] = station_row.loc['station_latitude']\n",
    "    future_exogenous_df['station_longitude'] = station_row.loc['station_longitude']\n",
    "    future_exogenous_df['distance_km'] = future_exogenous_df.apply(calculate_distance, axis=1)\n",
    "    \n",
    "    # Calculate the crucial 'is_within_typhoon_radius' feature\n",
    "    future_exogenous_df['is_within_typhoon_radius'] = (\n",
    "        future_exogenous_df['distance_km'] < future_exogenous_df['long50']\n",
    "    ).astype(int)\n",
    "\n",
    "    # --- STEP 1: Wind Speed Data Preparation ---\n",
    "\n",
    "    # 1. Load and prepare individual weather station data (Guanyin)\n",
    "    file_path = 'diem-john/qfl-pinns/QFL-PINNS-9852d42b191fec7add6a318f73b56ab6d69b701c/data/indiv_weather_station/Guanyin.csv'\n",
    "    guanyin_df = pd.read_csv(file_path).fillna(0)\n",
    "\n",
    "    # Rename columns and ensure datetime format\n",
    "    time_col = [col for col in guanyin_df.columns if 'time' in col.lower()][0]\n",
    "    guanyin_df['time'] = pd.to_datetime(guanyin_df[time_col], format='mixed', dayfirst=True)\n",
    "    guanyin_df.columns = ['time_Guanyin', 'air_pressure', 'temperature',\n",
    "                          'relative_humidity', 'wind_speed',\n",
    "                          'wind_direction', 'gust_max', 'gust_max_dir',\n",
    "                          'precipitation', 'solar_rad', 'time']\n",
    "    guanyin_df.drop(columns=['time_Guanyin'], inplace=True)\n",
    "    guanyin_df = guanyin_df[(guanyin_df['time'].dt.year >= 2015) & (guanyin_df['time'].dt.year <= 2021)].copy()\n",
    "    guanyin_df['station'] = station_name\n",
    "\n",
    "    # 2. Merge all historical data: Weather Station + Coordinates + Typhoon\n",
    "    guanyin_df = pd.merge(guanyin_df, station_coords[station_coords['station'] == station_name], on='station', how='left')\n",
    "    merged_data_historical = pd.merge_asof(\n",
    "        guanyin_df.sort_values('time'),\n",
    "        typhoon_data_hist.sort_values('time'),\n",
    "        on='time',\n",
    "        direction='nearest'\n",
    "    )\n",
    "    merged_data_historical.rename(columns={'wind_speed': 'wnd_s_max', 'lat': 'typhoon_lat', 'lng': 'typhoon_lng'}, inplace=True)\n",
    "    merged_data_historical['distance_km'] = merged_data_historical.apply(calculate_distance, axis=1)\n",
    "    merged_data_historical.rename(columns={'wnd_s_max': 'wind_speed'}, inplace=True)\n",
    "    \n",
    "    # 3. Clean and Select Final Historical Features\n",
    "    # The model input is fixed to the 9 weather station features for this prediction step.\n",
    "    all_historical_cols = merged_data_historical.columns.tolist()\n",
    "    cols_to_drop = [col for col in all_historical_cols if col not in features and col != 'time']\n",
    "    merged_data_historical.drop(columns=cols_to_drop, inplace=True)\n",
    "    \n",
    "    merged_data_historical.set_index('time', inplace=True)\n",
    "    merged_data_historical.dropna(inplace=True)\n",
    "\n",
    "    # 4. Scaling the data (MinMaxScaler)\n",
    "    scaler_features = MinMaxScaler()\n",
    "    scaler_target = MinMaxScaler()\n",
    "    merged_data_historical[features] = scaler_features.fit_transform(merged_data_historical[features])\n",
    "    merged_data_historical[target_features] = scaler_target.fit_transform(merged_data_historical[target_features])\n",
    "\n",
    "    # --- STEP 3: Forecast Wind Speed ---\n",
    "\n",
    "    # Run the forecast with the final 48 steps of historical data\n",
    "    wind_speed_forecast = predict_wind_speed(\n",
    "        model=model,\n",
    "        historical_df=merged_data_historical,\n",
    "        features=features,\n",
    "        scaler_target=scaler_target,\n",
    "        SEQUENCE_LENGTH=SEQUENCE_SIZE\n",
    "    )\n",
    "\n",
    "    # Output the final 24-hour forecast\n",
    "    forecast_df = pd.DataFrame({\n",
    "        'Time': forecast_times,\n",
    "        'Forecasted Wind Speed (m/s)': wind_speed_forecast.flatten()[:TARGET_WINDOW]\n",
    "    })\n",
    "\n",
    "    print(f\"\\nâœ… Steps 1-3 Complete: Wind Speed Forecast for {station_name}\")\n",
    "    print(\"\\n--- Exogenous Data Preview (Typhoon Track, Wind, Radius, & Distance) ---\")\n",
    "    print(future_exogenous_df[['time', 'lat', 'lng', 'wind', 'long50', 'distance_km', 'is_within_typhoon_radius']].head().to_markdown(index=False))\n",
    "    print(\"\\n--- 24-Hour Wind Speed Forecast (Step 3 Output) ---\")\n",
    "    print(forecast_df.to_markdown(index=False))\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: A data file was not found. Please ensure all data files are uploaded. {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during the forecasting process: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c5d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "j3_env",
   "language": "python",
   "name": "j3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
